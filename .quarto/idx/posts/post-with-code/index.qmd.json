{"title":"Assignment 3: Mucking up a Visualization","markdown":{"yaml":{"title":"Assignment 3: Mucking up a Visualization","author":"John Cambareri","date":"2025-02-17","categories":["news","code","analysis"],"image":"image.jpg","jupyter":"python3","format":{"html":{"code-fold":true}},"editor":"visual"},"headingText":"Combining NSF and NIH Data","containsRefs":false,"markdown":"\n\nThis downloads University of Idaho research expenditure data from the National Science Foundation (NSF) and the National Institutes of Health (NIH). Then, this creates a visualization, and finally, this intentionally makes it bad.\n\n\n### Step 1: Collecting the NSF Data\n\n```{python}\nimport requests\nfrom datetime import datetime\nimport pandas as pd\nimport re\nimport numpy as np\nimport json\n```\n\n### Initialize variables for the NSF data\n\n```{python}\nbase_url = \"https://www.research.gov/awardapi-service/v1/awards.json?awardeeName=%22regents+of+the+university+of+idaho%22\"\n\nprintFields = \"rpp,offset,id,agency,awardeeCity,awardeeCountryCode,awardeeDistrictCode,awardeeName,\\\n                awardeeStateCode,awardeeZipCode,cfdaNumber,coPDPI,date,startDate,expDate,estimatedTotalAmt,\\\n                fundsObligatedAmt,ueiNumber,fundProgramName,parentUeiNumber,pdPIName,perfCity,perfCountryCode,\\\n                perfDistrictCode,perfLocation,perfStateCode,perfZipCode,poName,primaryProgram,transType,title,\\\n                awardee,poPhone,poEmail,awardeeAddress,perfAddress,publicationResearch,publicationConference,\\\n                fundAgencyCode,awardAgencyCode,projectOutComesReport,abstractText,piFirstName,piMiddeInitial,\\\n                piLastName,piEmail\"\n\n# Initialize an empty DataFrame to store results\nall_awards = pd.DataFrame()\n\n# Number of results per page (as per API settings)\nresults_per_page = 25\n\n# Variable to keep track of the current page number\ncurrent_page = 1\n\n# Variable to control the loop\nkeep_going = True\n```\n\n### Extract data from the NSF website\n\n```{python echo=TRUE, results='hide'}\n\nwhile keep_going:\n    # Calculate the offset for the current page\n    offset = (current_page - 1) * results_per_page + 1\n\n    # Construct the full URL with offset\n    url = f\"{base_url}&offset={offset}&printFields={printFields}\"\n\n    # Make the API call\n    response = requests.get(url)\n\n    # Check if the call was successful\n    if response.status_code == 200:\n        # Extract and parse the JSON data\n        parsed_data = response.json()\n\n        # Extract the 'award' data and add to the all_awards DataFrame\n        awards_data = pd.json_normalize(parsed_data['response']['award'])\n        all_awards = pd.concat([all_awards, awards_data], ignore_index=True)\n\n        # Debug: Print the current page number and number of awards fetched\n        print(f\"Page: {current_page} - Awards fetched: {len(awards_data['id'])}\")\n\n        # Check if the current page has less than results_per_page awards, then it's the last page\n        if len(awards_data['id']) < results_per_page:\n            keep_going = False\n        else:\n            current_page += 1\n    else:\n        print(f\"Failed to fetch data: Status code {response.status_code}\")\n        keep_going = False\n```\n\n### Save data into csv file\n\nOptional: Uncomment the 'to_csv' command by removing the '\\#' to save the result of the extraction to a CSV file. If you want to load the data from the CSV file instead of redoing the NSF extraction, uncomment the read_csv command and run it as well.\n\n```{python}\n#all_awards.to_csv(\"UINSF.csv\", index=False)\n#all_awards = pd.read_csv(\"UINSF.csv\")\n```\n\nIf we print out the resulting dataframe now, there is a lot of data - too much, in fact.\n\n```{python}\nall_awards\n```\n\nWe will reduce the amount of columns, by only grabbing the relevant ones.\n\n```{python}\nreducedCols = all_awards[[\"cfdaNumber\", \"estimatedTotalAmt\", \"fundsObligatedAmt\", \"fundProgramName\",\\\n                          \"id\", \"pdPIName\", \"piFirstName\", \"piMiddeInitial\", \"piLastName\", \"poName\",\\\n                          \"date\", \"startDate\", \"expDate\", \"title\", \"coPDPI\"]].copy()\n```\n\nNow we clean up the columns a bit.\n\n```{python}\n#change formatting of monetary data from int to float\nreducedCols[\"estimatedTotalAmt\"] = reducedCols[\"estimatedTotalAmt\"].astype(float)\n\n#turn dates into pandas dates\nreducedCols[\"date\"] = pd.to_datetime(reducedCols[\"date\"])\nreducedCols[\"startDate\"] = pd.to_datetime(reducedCols[\"startDate\"])\nreducedCols[\"expDate\"] = pd.to_datetime(reducedCols[\"expDate\"])\n\n#only grab recent articles\ncurrentData = reducedCols[reducedCols[\"expDate\"] > pd.to_datetime(\"2019-01-01\")].copy()\n\n#remove Nulls/NAs from the Co-PI column\ncurrentData['coPDPI'] = [ [] if x is np.nan else x for x in currentData['coPDPI']]\n\n#rename dataframe\nNSFPIData = currentData\n```\n\n### Co-PI Information\n\nIn this dataframe, some of the PIs have 1 or more Co-PIs associated with them.\n\nHere we shall create a new dataframe from the PI dataframe; only those with at least one Co-PI are kept.\n\n```{python}\nNSFcoPIData = currentData[currentData[\"coPDPI\"].str.len() > 0]\n```\n\nNext, we will make it so that each element in the list gets seperated into a different row. This is done using the explode() function.\n\n```{python}\nNSFcoPIData = NSFcoPIData.explode(\"coPDPI\")\n```\n\n# Step 2: NIH Data\n\nAttaining the NIH data is a little different than attaining the NSF data, so a slightly different method will need to be used here. The code block below will use an API request to request the information from the NSF website. The result will then be saved into a JSON file, from which we will extract the data from into a dataframe.\n\n```{python}\n#| results: 'hide'\n\n# Define the current year and calculate the starting fiscal year (6 years ago; 2019)\ncurrent_year = datetime.now().year\nstart_fiscal_year = current_year - 6\n\n# Define the API URL and endpoint\nurl = \"https://api.reporter.nih.gov/v2/projects/search\"\n\n# Define the API request payload\npayload = {\n    \"criteria\": {\n        \"org_names\": [\"UNIVERSITY OF IDAHO\"],  # Filter for the University of Idaho\n        \"fiscal_years\": list(range(start_fiscal_year, current_year + 1)),  # Last 5 years\n        \"newly_added_projects_only\": False  # Include all projects, not just newly added ones\n    },\n    \"include_fields\": [\n        \"ApplId\", \"SubprojectId\", \"FiscalYear\", \"ProjectNum\", \"ProjectSerialNum\",\n        \"Organization\", \"OrganizationType\", \"AwardType\", \"ActivityCode\", \"AwardAmount\",\n        \"ProjectNumSplit\", \"PrincipalInvestigators\", \"ProgramOfficers\", \"AgencyIcAdmin\",\n        \"AgencyIcFundings\", \"CongDist\", \"ProjectStartDate\", \"ProjectEndDate\", \"FullFoa\",\n        \"FullStudySection\", \"AwardNoticeDate\", \"CoreProjectNum\", \"PrefTerms\", \"ProjectTitle\",\n        \"PhrText\", \"SpendingCategoriesDesc\", \"ArraFunded\", \"BudgetStart\", \"BudgetEnd\",\n        \"CfdaCode\", \"FundingMechanism\", \"DirectCostAmt\", \"IndirectCostAmt\"\n    ],\n    \"offset\": 0,  # Start from the first record\n    \"limit\": 500,  # Number of records to fetch per request, can be adjusted\n    \"sort_field\": \"project_start_date\",\n    \"sort_order\": \"desc\"\n}\n\n# Make the API request\nresponse = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(payload))\n \n# Check for a successful response\nif response.status_code == 200:\n    data = response.json()  # Parse the JSON response\n    with open('university_of_idaho_awards_last_5_years.json', 'w') as f:\n        json.dump(data, f, indent=4)\n    print(\"Data successfully downloaded and saved to 'university_of_idaho_awards_2019_2024.json'\")\nelse:\n    print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n```\n\n```{python}\n# Load the JSON data from the file, replace the name with whatever file you want to load from\nwith open('university_of_idaho_awards_last_5_years.json', 'r') as f:\n    data = json.load(f)\n    \n# Extract relevant fields and create a list of dictionaries\nawards_data = []\nfor project in data.get('results', []):\n    org_name = project.get('organization', {}).get('org_name', '')\n    project_num = project.get('project_num', '')\n    project_title = project.get('project_title', '')\n   \n    # Principal Investigators (concatenating names if more than one PI)\n    principal_investigators = \", \".join(\n        [pi.get('full_name', '') for pi in project.get('principal_investigators', [])]\n    )\n    \n    # Extract First Names and Last Names for ease of use later\n    principal_investigators_first_name = \", \".join(\n        [pi.get('first_name', '') for pi in project.get('principal_investigators', [])]\n    )\n    \n    principal_investigators_last_name = \", \".join(\n        [pi.get('last_name', '') for pi in project.get('principal_investigators', [])]\n    )\n   \n    direct_cost_amt = project.get('direct_cost_amt', 0)\n   \n    awards_data.append({\n        \"Organization\": org_name,\n        \"ProjectNum\": project_num,\n        \"ProjectTitle\": project_title,\n        \"PrincipalInvestigators\": principal_investigators,\n        \"PrincipalInvestigatorsFirstName\": principal_investigators_first_name,\n        \"PrincipalInvestigatorsLastName\": principal_investigators_last_name,\n        \"DirectCostAmt\": direct_cost_amt\n    })\n    \ndf = pd.DataFrame(awards_data)\n```\n\n### Split columns\n\nUnlike in the NSF data, NIH data can list multiple PIs. Therefore, each of the relevant columns need to be split in case there is more than one present.\n\n```{python}\ndf[\"PrincipalInvestigators\"] = df[\"PrincipalInvestigators\"].str.split(',')\ndf[\"PrincipalInvestigatorsFirstName\"] = df[\"PrincipalInvestigatorsFirstName\"].str.split(',')\ndf[\"PrincipalInvestigatorsLastName\"] = df[\"PrincipalInvestigatorsLastName\"].str.split(',')\n```\n\nThe explode() function sees use again here.\n\n```{python}\nNIHData = df.explode([\"PrincipalInvestigators\", \"PrincipalInvestigatorsFirstName\", \\\n                      \"PrincipalInvestigatorsLastName\"])\n```\n\nTypecast relevant information from int to float\n\n```{python}\nNIHData[\"DirectCostAmt\"] = NIHData[\"DirectCostAmt\"].astype(float)\n```\n\n# Step 3: Name Cleanup\n\nSince NIH and NSF display their names differently, simply combining the two databases together can result in some of the data for faculty being split up across the two in the event that they submitted a research grant for both institutions.\n\nFirst, we shall define a couple of helper functions that will use regular expressions to help sort out inconsistencies.\n\n```{python}\n#Sometimes a middle name is shown in the name tab in the Co-PI table, which is unwanted here.\ndef removeMiddleName(name):\n    parts = name.split()\n    if len(parts) <= 2:\n        return name\n    return parts[0] + \" \" + parts[-1]\n\nNSFcoPIData[\"coPIFullName\"] = NSFcoPIData[\"coPDPI\"].apply(removeMiddleName)\n\n#remove whitespace from start of the name\ndef removeInitialSpace(name):\n    regex = r\"^\\s\"\n    while re.match(regex, name):\n        name = name[1:]\n        \n    return name\n        \nNIHData[\"PrincipalInvestigatorsFirstName\"] = NIHData[\"PrincipalInvestigatorsFirstName\"].apply(removeInitialSpace)\nNIHData[\"PrincipalInvestigatorsLastName\"] = NIHData[\"PrincipalInvestigatorsLastName\"].apply(removeInitialSpace)\n```\n\n### Add Full Name column\n\nFor the NSF PI data and the NIH data, middle names are applied inconsistently. Thus, instead of using the removeMiddleName() function as done above, we simply take the first and last name columns and add them together.\n\nCapitalization is also an inconsistency between the two institutions. To fix this, all names will be capitalized.\n\n```{python}\nNSFPIData[\"piFullName\"] = NSFPIData[\"piFirstName\"] + \" \" + NSFPIData[\"piLastName\"]\nNIHData[\"PIName\"] = NIHData[\"PrincipalInvestigatorsFirstName\"] + \" \" + NIHData[\"PrincipalInvestigatorsLastName\"]\n\nNSFPIData[\"piFullName\"] = NSFPIData[\"piFullName\"].str.upper()\nNSFcoPIData[\"coPIFullName\"] = NSFcoPIData[\"coPIFullName\"].str.upper()\nNIHData[\"PIName\"] = NIHData[\"PIName\"].str.upper()\n```\n\nA few exceptions still remain, so these have to be fixed manually.\n\n```{python}\nNSFcoPIData.loc[NSFcoPIData[\"coPIFullName\"] == \"TERESA COHN\", \"coPIFullName\"] = \"TERESA CAVAZOS COHN\"\nNSFcoPIData.loc[NSFcoPIData[\"coPIFullName\"] == \"JAGDISH PATEL\", \"coPIFullName\"] = \"JAGDISH SURESH PATEL\"\n```\n\n# Step 4: Making the Plot\n\nNow that all of the data is ready to go, it's time to create a graph that will visualize the data.\n\nThe NIH and NSF PI data combine together nicely, but the Co-PI data does not work well when added cumulatively with the PI data. Therefore, one solution is to make two graphs - a bar graph with the PI data, and a scatter/circle plot for the NSF data.\n\nWe will use plotly's graph function as follows. First we import plotly's graph_objects library. Since we want to make two plots, we can also use plotly's subplot library as well.\n\n```{python}\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n```\n\nNow we define the overall structure of the subplot. Each parameter will be as follows:\n\nWe want the plots to be side-by-side, so we want 1 row and 2 columns.\n\nWe want the data points on the y axis (in this case, it's the PI/Co-PI's names) to be the same across the subplots, and we can implement this with the shared_yaxes parameter.\n\nHorizontal spacing just ensures that the space between the two halves of the overall plot are minimized.\n\nNote that in this code block below, the code is commented. This is on purpose, to avoid the plot information from being displayed too early.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n'''\n```\n\nFirst, We will add the NSF PI data to the graph. This will be a bar function.\n\nWe use x for the total money amount, and y for the names of the PIs.\n\nThe 'text' parameter will cause the bar to display a value on the bar itself; in this case we want the same as the x axis (the total money amount). \"Inside\" means that it will be positioned in the bar itself, not directly above or to the side of the bar.\n\nSetting orientation to 'h' lets plotly know that its a sideways plot; the bar graphs will be coming from left-to-right instead of bottom-to-top.\n\nFinally, we set a 'customdata' field. This is used with the hovertemplate directly below, in order to display data when the graph is moused over. \\<br\\> tags will cause a line break, and the \\$.2s field causes the money to be rounded to the nearest 2 significant digits.\n\nFinally, the row and column position of the bar graph in the overall graph is displayed.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n'''\n```\n\nNext, we do the same thing, but with the NIH data instead. A couple of things to note here:\n\nFirst, This will be in the same row and column as the NSF data.\n\nSecond, the NIH data does not provide co-PI information, so the customdata parameter here is not as large.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n'''\n```\n\nHere we update the graph to show the horizontal axis on the bar chart itself, to make readability better and to make it easier to associate items on the bar chart side of the graph with the items on the scatter plot side of the graph.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.update_yaxes(showgrid = True)\nNIH_NSF.update_traces(texttemplate = '%{text:.2s}')\n'''\n```\n\nLastly, we implement the Scatter plot portion of the graph. This has a few different parameters than the bar graph; in this case, we see the mode of \"markers\".\n\nIn this case, we want the size of the scatter plot/bubble to be directly proportional to how much money the co-PI is responsible for, but we also want to set a cap on how large the bubbles can be, so there is a max() function in the sizeref() parameter as part of the marker parameter.\n\nFinally, to ensure it's not on the same part of the graph as the bar charts, this is placed in column 2.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n'''\n```\n\nNow we do one final update to the plot's layout.\n\nThe height function measures how large the graph will show. This size might not fit on everyone's page; adjust this if needed.\n\nSetting the barmode to 'stack' causes the two bar graphs (the NIH and NSF PI data) to stack on top of each other instead of being fitted side-to-side.\n\nWith the y axis being in 'total descending', this means that the data will be generally ordered from highest contribution to lowest. However, there is a bug with plotly that causes not all the data to be in the right order when grouped in a subplot.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data\"\n)\n'''\n```\n\nThis command will create the plot.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.show()\n'''\n```\n\nCombining all the code snippets will create the plot. In this plot, you can do the following:\n\nMousing over any datapoint (bar graph/scatter plot) will show you data regarding that particular grant, including PI, money allocated, title, associated co-PI or PI if they exist, etc.\n\nIf the data is too small to read properly, you can click and hold on the graph itself to draw an area on the graph; releasing the mouse will zoom in on the area that you selected. Double-click the graph to return it to regular size.\n\n```{python}\n#|column: page\n\nimport plotly.io as pio\npio.renderers.default = \"iframe\"\n\nNIH_NSF = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n\nNIH_NSF.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n\nNIH_NSF.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n\nNIH_NSF.update_yaxes(showgrid = True)\nNIH_NSF.update_traces(texttemplate = '%{text:.2s}')\n\nNIH_NSF.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n\nNIH_NSF.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data\"\n)\n\nNIH_NSF.show()\n```\n\n# Mucking up the visualization\n\nNow that we have a graph, it's now time to intentionally mess it up. This can be done by obscuring the differences between the NIH and NSF data. We can do this by intentionally making the marker_color of both the NIH and NSF data blue. To make it so that there is a difference, the opacity of the NIH data will be set to 0.75. Therefore, there will be a difference between the two, but it won't be as obvious.\n\nZoom into the graph by dragging an area over the left side of the graph to see this in action.\n\n```{python}\n#|column: page\n\nNIH_NSF_bad = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n\nNIH_NSF_bad.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    marker_color = \"blue\",\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    marker_color = \"blue\",\n    opacity = 0.75,\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad.update_yaxes(showgrid = True)\nNIH_NSF_bad.update_traces(texttemplate = '%{text:.2s}')\n\nNIH_NSF_bad.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n\nNIH_NSF_bad.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data (bad, opacity)\"\n)\n\nNIH_NSF_bad.show()\n```\n\nNow, we do a second example. In this case, instead of reducing the opacity, we instead make similar patterns in the bars themselves. In this example, we give the NSF data a forward slash '/' pattern, and the NIH data a backward slash '\\\\' pattern. Like before, this intentionally obfuscates the distinction between the two different institutions that provide the research funding.\n\n```{python}\n#|column: page\n\nNIH_NSF_bad2 = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n\nNIH_NSF_bad2.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    marker_color = \"blue\",\n    marker_pattern_shape = \"/\",\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad2.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    marker_color = \"blue\",\n    marker_pattern_shape = \"\\\\\",\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad2.update_yaxes(showgrid = True)\nNIH_NSF_bad2.update_traces(texttemplate = '%{text:.2s}')\n\nNIH_NSF_bad2.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n\nNIH_NSF_bad2.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data (bad, bar patterns)\"\n)\n\nNIH_NSF_bad2.show()\n```\n","srcMarkdownNoYaml":"\n\nThis downloads University of Idaho research expenditure data from the National Science Foundation (NSF) and the National Institutes of Health (NIH). Then, this creates a visualization, and finally, this intentionally makes it bad.\n\n# Combining NSF and NIH Data\n\n### Step 1: Collecting the NSF Data\n\n```{python}\nimport requests\nfrom datetime import datetime\nimport pandas as pd\nimport re\nimport numpy as np\nimport json\n```\n\n### Initialize variables for the NSF data\n\n```{python}\nbase_url = \"https://www.research.gov/awardapi-service/v1/awards.json?awardeeName=%22regents+of+the+university+of+idaho%22\"\n\nprintFields = \"rpp,offset,id,agency,awardeeCity,awardeeCountryCode,awardeeDistrictCode,awardeeName,\\\n                awardeeStateCode,awardeeZipCode,cfdaNumber,coPDPI,date,startDate,expDate,estimatedTotalAmt,\\\n                fundsObligatedAmt,ueiNumber,fundProgramName,parentUeiNumber,pdPIName,perfCity,perfCountryCode,\\\n                perfDistrictCode,perfLocation,perfStateCode,perfZipCode,poName,primaryProgram,transType,title,\\\n                awardee,poPhone,poEmail,awardeeAddress,perfAddress,publicationResearch,publicationConference,\\\n                fundAgencyCode,awardAgencyCode,projectOutComesReport,abstractText,piFirstName,piMiddeInitial,\\\n                piLastName,piEmail\"\n\n# Initialize an empty DataFrame to store results\nall_awards = pd.DataFrame()\n\n# Number of results per page (as per API settings)\nresults_per_page = 25\n\n# Variable to keep track of the current page number\ncurrent_page = 1\n\n# Variable to control the loop\nkeep_going = True\n```\n\n### Extract data from the NSF website\n\n```{python echo=TRUE, results='hide'}\n\nwhile keep_going:\n    # Calculate the offset for the current page\n    offset = (current_page - 1) * results_per_page + 1\n\n    # Construct the full URL with offset\n    url = f\"{base_url}&offset={offset}&printFields={printFields}\"\n\n    # Make the API call\n    response = requests.get(url)\n\n    # Check if the call was successful\n    if response.status_code == 200:\n        # Extract and parse the JSON data\n        parsed_data = response.json()\n\n        # Extract the 'award' data and add to the all_awards DataFrame\n        awards_data = pd.json_normalize(parsed_data['response']['award'])\n        all_awards = pd.concat([all_awards, awards_data], ignore_index=True)\n\n        # Debug: Print the current page number and number of awards fetched\n        print(f\"Page: {current_page} - Awards fetched: {len(awards_data['id'])}\")\n\n        # Check if the current page has less than results_per_page awards, then it's the last page\n        if len(awards_data['id']) < results_per_page:\n            keep_going = False\n        else:\n            current_page += 1\n    else:\n        print(f\"Failed to fetch data: Status code {response.status_code}\")\n        keep_going = False\n```\n\n### Save data into csv file\n\nOptional: Uncomment the 'to_csv' command by removing the '\\#' to save the result of the extraction to a CSV file. If you want to load the data from the CSV file instead of redoing the NSF extraction, uncomment the read_csv command and run it as well.\n\n```{python}\n#all_awards.to_csv(\"UINSF.csv\", index=False)\n#all_awards = pd.read_csv(\"UINSF.csv\")\n```\n\nIf we print out the resulting dataframe now, there is a lot of data - too much, in fact.\n\n```{python}\nall_awards\n```\n\nWe will reduce the amount of columns, by only grabbing the relevant ones.\n\n```{python}\nreducedCols = all_awards[[\"cfdaNumber\", \"estimatedTotalAmt\", \"fundsObligatedAmt\", \"fundProgramName\",\\\n                          \"id\", \"pdPIName\", \"piFirstName\", \"piMiddeInitial\", \"piLastName\", \"poName\",\\\n                          \"date\", \"startDate\", \"expDate\", \"title\", \"coPDPI\"]].copy()\n```\n\nNow we clean up the columns a bit.\n\n```{python}\n#change formatting of monetary data from int to float\nreducedCols[\"estimatedTotalAmt\"] = reducedCols[\"estimatedTotalAmt\"].astype(float)\n\n#turn dates into pandas dates\nreducedCols[\"date\"] = pd.to_datetime(reducedCols[\"date\"])\nreducedCols[\"startDate\"] = pd.to_datetime(reducedCols[\"startDate\"])\nreducedCols[\"expDate\"] = pd.to_datetime(reducedCols[\"expDate\"])\n\n#only grab recent articles\ncurrentData = reducedCols[reducedCols[\"expDate\"] > pd.to_datetime(\"2019-01-01\")].copy()\n\n#remove Nulls/NAs from the Co-PI column\ncurrentData['coPDPI'] = [ [] if x is np.nan else x for x in currentData['coPDPI']]\n\n#rename dataframe\nNSFPIData = currentData\n```\n\n### Co-PI Information\n\nIn this dataframe, some of the PIs have 1 or more Co-PIs associated with them.\n\nHere we shall create a new dataframe from the PI dataframe; only those with at least one Co-PI are kept.\n\n```{python}\nNSFcoPIData = currentData[currentData[\"coPDPI\"].str.len() > 0]\n```\n\nNext, we will make it so that each element in the list gets seperated into a different row. This is done using the explode() function.\n\n```{python}\nNSFcoPIData = NSFcoPIData.explode(\"coPDPI\")\n```\n\n# Step 2: NIH Data\n\nAttaining the NIH data is a little different than attaining the NSF data, so a slightly different method will need to be used here. The code block below will use an API request to request the information from the NSF website. The result will then be saved into a JSON file, from which we will extract the data from into a dataframe.\n\n```{python}\n#| results: 'hide'\n\n# Define the current year and calculate the starting fiscal year (6 years ago; 2019)\ncurrent_year = datetime.now().year\nstart_fiscal_year = current_year - 6\n\n# Define the API URL and endpoint\nurl = \"https://api.reporter.nih.gov/v2/projects/search\"\n\n# Define the API request payload\npayload = {\n    \"criteria\": {\n        \"org_names\": [\"UNIVERSITY OF IDAHO\"],  # Filter for the University of Idaho\n        \"fiscal_years\": list(range(start_fiscal_year, current_year + 1)),  # Last 5 years\n        \"newly_added_projects_only\": False  # Include all projects, not just newly added ones\n    },\n    \"include_fields\": [\n        \"ApplId\", \"SubprojectId\", \"FiscalYear\", \"ProjectNum\", \"ProjectSerialNum\",\n        \"Organization\", \"OrganizationType\", \"AwardType\", \"ActivityCode\", \"AwardAmount\",\n        \"ProjectNumSplit\", \"PrincipalInvestigators\", \"ProgramOfficers\", \"AgencyIcAdmin\",\n        \"AgencyIcFundings\", \"CongDist\", \"ProjectStartDate\", \"ProjectEndDate\", \"FullFoa\",\n        \"FullStudySection\", \"AwardNoticeDate\", \"CoreProjectNum\", \"PrefTerms\", \"ProjectTitle\",\n        \"PhrText\", \"SpendingCategoriesDesc\", \"ArraFunded\", \"BudgetStart\", \"BudgetEnd\",\n        \"CfdaCode\", \"FundingMechanism\", \"DirectCostAmt\", \"IndirectCostAmt\"\n    ],\n    \"offset\": 0,  # Start from the first record\n    \"limit\": 500,  # Number of records to fetch per request, can be adjusted\n    \"sort_field\": \"project_start_date\",\n    \"sort_order\": \"desc\"\n}\n\n# Make the API request\nresponse = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(payload))\n \n# Check for a successful response\nif response.status_code == 200:\n    data = response.json()  # Parse the JSON response\n    with open('university_of_idaho_awards_last_5_years.json', 'w') as f:\n        json.dump(data, f, indent=4)\n    print(\"Data successfully downloaded and saved to 'university_of_idaho_awards_2019_2024.json'\")\nelse:\n    print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n```\n\n```{python}\n# Load the JSON data from the file, replace the name with whatever file you want to load from\nwith open('university_of_idaho_awards_last_5_years.json', 'r') as f:\n    data = json.load(f)\n    \n# Extract relevant fields and create a list of dictionaries\nawards_data = []\nfor project in data.get('results', []):\n    org_name = project.get('organization', {}).get('org_name', '')\n    project_num = project.get('project_num', '')\n    project_title = project.get('project_title', '')\n   \n    # Principal Investigators (concatenating names if more than one PI)\n    principal_investigators = \", \".join(\n        [pi.get('full_name', '') for pi in project.get('principal_investigators', [])]\n    )\n    \n    # Extract First Names and Last Names for ease of use later\n    principal_investigators_first_name = \", \".join(\n        [pi.get('first_name', '') for pi in project.get('principal_investigators', [])]\n    )\n    \n    principal_investigators_last_name = \", \".join(\n        [pi.get('last_name', '') for pi in project.get('principal_investigators', [])]\n    )\n   \n    direct_cost_amt = project.get('direct_cost_amt', 0)\n   \n    awards_data.append({\n        \"Organization\": org_name,\n        \"ProjectNum\": project_num,\n        \"ProjectTitle\": project_title,\n        \"PrincipalInvestigators\": principal_investigators,\n        \"PrincipalInvestigatorsFirstName\": principal_investigators_first_name,\n        \"PrincipalInvestigatorsLastName\": principal_investigators_last_name,\n        \"DirectCostAmt\": direct_cost_amt\n    })\n    \ndf = pd.DataFrame(awards_data)\n```\n\n### Split columns\n\nUnlike in the NSF data, NIH data can list multiple PIs. Therefore, each of the relevant columns need to be split in case there is more than one present.\n\n```{python}\ndf[\"PrincipalInvestigators\"] = df[\"PrincipalInvestigators\"].str.split(',')\ndf[\"PrincipalInvestigatorsFirstName\"] = df[\"PrincipalInvestigatorsFirstName\"].str.split(',')\ndf[\"PrincipalInvestigatorsLastName\"] = df[\"PrincipalInvestigatorsLastName\"].str.split(',')\n```\n\nThe explode() function sees use again here.\n\n```{python}\nNIHData = df.explode([\"PrincipalInvestigators\", \"PrincipalInvestigatorsFirstName\", \\\n                      \"PrincipalInvestigatorsLastName\"])\n```\n\nTypecast relevant information from int to float\n\n```{python}\nNIHData[\"DirectCostAmt\"] = NIHData[\"DirectCostAmt\"].astype(float)\n```\n\n# Step 3: Name Cleanup\n\nSince NIH and NSF display their names differently, simply combining the two databases together can result in some of the data for faculty being split up across the two in the event that they submitted a research grant for both institutions.\n\nFirst, we shall define a couple of helper functions that will use regular expressions to help sort out inconsistencies.\n\n```{python}\n#Sometimes a middle name is shown in the name tab in the Co-PI table, which is unwanted here.\ndef removeMiddleName(name):\n    parts = name.split()\n    if len(parts) <= 2:\n        return name\n    return parts[0] + \" \" + parts[-1]\n\nNSFcoPIData[\"coPIFullName\"] = NSFcoPIData[\"coPDPI\"].apply(removeMiddleName)\n\n#remove whitespace from start of the name\ndef removeInitialSpace(name):\n    regex = r\"^\\s\"\n    while re.match(regex, name):\n        name = name[1:]\n        \n    return name\n        \nNIHData[\"PrincipalInvestigatorsFirstName\"] = NIHData[\"PrincipalInvestigatorsFirstName\"].apply(removeInitialSpace)\nNIHData[\"PrincipalInvestigatorsLastName\"] = NIHData[\"PrincipalInvestigatorsLastName\"].apply(removeInitialSpace)\n```\n\n### Add Full Name column\n\nFor the NSF PI data and the NIH data, middle names are applied inconsistently. Thus, instead of using the removeMiddleName() function as done above, we simply take the first and last name columns and add them together.\n\nCapitalization is also an inconsistency between the two institutions. To fix this, all names will be capitalized.\n\n```{python}\nNSFPIData[\"piFullName\"] = NSFPIData[\"piFirstName\"] + \" \" + NSFPIData[\"piLastName\"]\nNIHData[\"PIName\"] = NIHData[\"PrincipalInvestigatorsFirstName\"] + \" \" + NIHData[\"PrincipalInvestigatorsLastName\"]\n\nNSFPIData[\"piFullName\"] = NSFPIData[\"piFullName\"].str.upper()\nNSFcoPIData[\"coPIFullName\"] = NSFcoPIData[\"coPIFullName\"].str.upper()\nNIHData[\"PIName\"] = NIHData[\"PIName\"].str.upper()\n```\n\nA few exceptions still remain, so these have to be fixed manually.\n\n```{python}\nNSFcoPIData.loc[NSFcoPIData[\"coPIFullName\"] == \"TERESA COHN\", \"coPIFullName\"] = \"TERESA CAVAZOS COHN\"\nNSFcoPIData.loc[NSFcoPIData[\"coPIFullName\"] == \"JAGDISH PATEL\", \"coPIFullName\"] = \"JAGDISH SURESH PATEL\"\n```\n\n# Step 4: Making the Plot\n\nNow that all of the data is ready to go, it's time to create a graph that will visualize the data.\n\nThe NIH and NSF PI data combine together nicely, but the Co-PI data does not work well when added cumulatively with the PI data. Therefore, one solution is to make two graphs - a bar graph with the PI data, and a scatter/circle plot for the NSF data.\n\nWe will use plotly's graph function as follows. First we import plotly's graph_objects library. Since we want to make two plots, we can also use plotly's subplot library as well.\n\n```{python}\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n```\n\nNow we define the overall structure of the subplot. Each parameter will be as follows:\n\nWe want the plots to be side-by-side, so we want 1 row and 2 columns.\n\nWe want the data points on the y axis (in this case, it's the PI/Co-PI's names) to be the same across the subplots, and we can implement this with the shared_yaxes parameter.\n\nHorizontal spacing just ensures that the space between the two halves of the overall plot are minimized.\n\nNote that in this code block below, the code is commented. This is on purpose, to avoid the plot information from being displayed too early.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n'''\n```\n\nFirst, We will add the NSF PI data to the graph. This will be a bar function.\n\nWe use x for the total money amount, and y for the names of the PIs.\n\nThe 'text' parameter will cause the bar to display a value on the bar itself; in this case we want the same as the x axis (the total money amount). \"Inside\" means that it will be positioned in the bar itself, not directly above or to the side of the bar.\n\nSetting orientation to 'h' lets plotly know that its a sideways plot; the bar graphs will be coming from left-to-right instead of bottom-to-top.\n\nFinally, we set a 'customdata' field. This is used with the hovertemplate directly below, in order to display data when the graph is moused over. \\<br\\> tags will cause a line break, and the \\$.2s field causes the money to be rounded to the nearest 2 significant digits.\n\nFinally, the row and column position of the bar graph in the overall graph is displayed.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n'''\n```\n\nNext, we do the same thing, but with the NIH data instead. A couple of things to note here:\n\nFirst, This will be in the same row and column as the NSF data.\n\nSecond, the NIH data does not provide co-PI information, so the customdata parameter here is not as large.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n'''\n```\n\nHere we update the graph to show the horizontal axis on the bar chart itself, to make readability better and to make it easier to associate items on the bar chart side of the graph with the items on the scatter plot side of the graph.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.update_yaxes(showgrid = True)\nNIH_NSF.update_traces(texttemplate = '%{text:.2s}')\n'''\n```\n\nLastly, we implement the Scatter plot portion of the graph. This has a few different parameters than the bar graph; in this case, we see the mode of \"markers\".\n\nIn this case, we want the size of the scatter plot/bubble to be directly proportional to how much money the co-PI is responsible for, but we also want to set a cap on how large the bubbles can be, so there is a max() function in the sizeref() parameter as part of the marker parameter.\n\nFinally, to ensure it's not on the same part of the graph as the bar charts, this is placed in column 2.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n'''\n```\n\nNow we do one final update to the plot's layout.\n\nThe height function measures how large the graph will show. This size might not fit on everyone's page; adjust this if needed.\n\nSetting the barmode to 'stack' causes the two bar graphs (the NIH and NSF PI data) to stack on top of each other instead of being fitted side-to-side.\n\nWith the y axis being in 'total descending', this means that the data will be generally ordered from highest contribution to lowest. However, there is a bug with plotly that causes not all the data to be in the right order when grouped in a subplot.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data\"\n)\n'''\n```\n\nThis command will create the plot.\n\n```{python}\n#| results: 'hide'\n\n'''\nNIH_NSF.show()\n'''\n```\n\nCombining all the code snippets will create the plot. In this plot, you can do the following:\n\nMousing over any datapoint (bar graph/scatter plot) will show you data regarding that particular grant, including PI, money allocated, title, associated co-PI or PI if they exist, etc.\n\nIf the data is too small to read properly, you can click and hold on the graph itself to draw an area on the graph; releasing the mouse will zoom in on the area that you selected. Double-click the graph to return it to regular size.\n\n```{python}\n#|column: page\n\nimport plotly.io as pio\npio.renderers.default = \"iframe\"\n\nNIH_NSF = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n\nNIH_NSF.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n\nNIH_NSF.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n\nNIH_NSF.update_yaxes(showgrid = True)\nNIH_NSF.update_traces(texttemplate = '%{text:.2s}')\n\nNIH_NSF.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n\nNIH_NSF.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data\"\n)\n\nNIH_NSF.show()\n```\n\n# Mucking up the visualization\n\nNow that we have a graph, it's now time to intentionally mess it up. This can be done by obscuring the differences between the NIH and NSF data. We can do this by intentionally making the marker_color of both the NIH and NSF data blue. To make it so that there is a difference, the opacity of the NIH data will be set to 0.75. Therefore, there will be a difference between the two, but it won't be as obvious.\n\nZoom into the graph by dragging an area over the left side of the graph to see this in action.\n\n```{python}\n#|column: page\n\nNIH_NSF_bad = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n\nNIH_NSF_bad.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    marker_color = \"blue\",\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    marker_color = \"blue\",\n    opacity = 0.75,\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad.update_yaxes(showgrid = True)\nNIH_NSF_bad.update_traces(texttemplate = '%{text:.2s}')\n\nNIH_NSF_bad.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n\nNIH_NSF_bad.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data (bad, opacity)\"\n)\n\nNIH_NSF_bad.show()\n```\n\nNow, we do a second example. In this case, instead of reducing the opacity, we instead make similar patterns in the bars themselves. In this example, we give the NSF data a forward slash '/' pattern, and the NIH data a backward slash '\\\\' pattern. Like before, this intentionally obfuscates the distinction between the two different institutions that provide the research funding.\n\n```{python}\n#|column: page\n\nNIH_NSF_bad2 = make_subplots(\n    rows = 1,\n    cols = 2,\n    shared_yaxes = True,\n    horizontal_spacing = 0.02\n)\n\nNIH_NSF_bad2.add_trace(go.Bar(\n    x = NSFPIData[\"estimatedTotalAmt\"],\n    y = NSFPIData[\"piFullName\"],\n    text = NSFPIData[\"estimatedTotalAmt\"],\n    textposition = \"inside\",\n    name = \"Estimated Total Amount (As PI (NSF))\",\n    orientation = \"h\",\n    customdata = NSFPIData[[\"title\", \"coPDPI\"]],\n    marker_color = \"blue\",\n    marker_pattern_shape = \"/\",\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> CoPIs: %{customdata[1]}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad2.add_trace(go.Bar(\n    x = NIHData[\"DirectCostAmt\"],\n    y = NIHData[\"PIName\"],\n    text = NIHData[\"DirectCostAmt\"],\n    textposition = \"inside\",\n    name = \"Direct Cost Amount (As PI (NIH))\",\n    orientation = \"h\",\n    customdata = NIHData[\"ProjectTitle\"],\n    marker_color = \"blue\",\n    marker_pattern_shape = \"\\\\\",\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata}\"\n), row = 1, col = 1)\n\nNIH_NSF_bad2.update_yaxes(showgrid = True)\nNIH_NSF_bad2.update_traces(texttemplate = '%{text:.2s}')\n\nNIH_NSF_bad2.add_trace(go.Scatter(\n    x = NSFcoPIData[\"estimatedTotalAmt\"],\n    y = NSFcoPIData[\"coPIFullName\"],\n    name = \"Estimated Total Amount (As CoPI (NSF))\",\n    mode = 'markers',\n    marker = dict(\n        size = NSFcoPIData[\"estimatedTotalAmt\"],\n        sizemode = 'area',\n        sizeref = 2.*max(NSFcoPIData[\"estimatedTotalAmt\"])/(60**2),\n        sizemin = 4\n    ),\n    customdata = NSFcoPIData[[\"title\", \"pdPIName\"]],\n    hovertemplate = \"Name: %{y} <br> Amount: %{x:$.2s} <br> Title: %{customdata[0]} <br> PI: %{customdata[1]}\"\n), row = 1, col = 2)\n\nNIH_NSF_bad2.update_layout(\n    height = 1250,\n    barmode = \"stack\",\n    yaxis = {'categoryorder' : 'total descending'},\n    title_text = \"NIH and NSF Data (bad, bar patterns)\"\n)\n\nNIH_NSF_bad2.show()\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"visual","theme":"cosmo","title-block-banner":true,"title":"Assignment 3: Mucking up a Visualization","author":"John Cambareri","date":"2025-02-17","categories":["news","code","analysis"],"image":"image.jpg","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}